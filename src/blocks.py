import logging
import nltk
from typing import List, Dict, Any
from tqdm.notebook import tqdm
from collections import Counter
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize, sent_tokenize
from src.config import logger, APP_SETTINGS
from src import app_state
from src.utils import format_time
from src.youtube import get_youtube_chapters, get_youtube_video_chapters_api


def analyze_subtitles_into_blocks(subtitles, min_block_duration=60, min_pause_threshold=3, max_block_size=25):
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç —Å—É–±—Ç–∏—Ç—Ä—ã –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –±–ª–æ–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
    
    Args:
        subtitles: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å—É–±—Ç–∏—Ç—Ä–æ–≤
        min_block_duration: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±–ª–æ–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        min_pause_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –ø–∞—É–∑—ã –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –±–ª–æ–∫–æ–≤ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        max_block_size: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –≤ –æ–¥–Ω–æ–º –±–ª–æ–∫–µ
        
    Returns:
        –°–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤, –≥–¥–µ –∫–∞–∂–¥—ã–π –±–ª–æ–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ø–∏—Å–æ–∫ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    """
    if not subtitles or len(subtitles) < 5:
        # –ï—Å–ª–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –º–∞–ª–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–¥–∏–Ω –±–ª–æ–∫
        return [{
            "start_time": subtitles[0]["start"] if subtitles else 0,
            "end_time": subtitles[-1]["start"] + subtitles[-1].get("duration", 5) if subtitles else 0,
            "subtitles": subtitles,
            "content_text": " ".join([s.get("text", "") for s in subtitles]),
            "title": "–í–µ—Å—å –∫–æ–Ω—Ç–µ–Ω—Ç"
        }]
    
    blocks = []
    current_block = []
    current_block_text = ""
    
    for i, subtitle in enumerate(subtitles):
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π —Å—É–±—Ç–∏—Ç—Ä –≤ —Ç–µ–∫—É—â–∏–π –±–ª–æ–∫
        current_block.append(subtitle)
        current_block_text += " " + subtitle.get("text", "")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –±–ª–æ–∫
        should_split = False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—É–∑—ã
        if i < len(subtitles) - 1:
            next_subtitle = subtitles[i + 1]
            pause_duration = next_subtitle["start"] - (subtitle["start"] + subtitle.get("duration", 5))
            if pause_duration >= min_pause_threshold:
                should_split = True
                
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—Ä–∞ –±–ª–æ–∫–∞
        if len(current_block) >= max_block_size:
            should_split = True
            
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –±–ª–æ–∫, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ —Ä–∞–∑–¥–µ–ª–∏—Ç—å
        if should_split or i == len(subtitles) - 1:
            if current_block:
                block_start_time = current_block[0]["start"]
                block_end_time = current_block[-1]["start"] + current_block[-1].get("duration", 5)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±–ª–æ–∫–∞
                if block_end_time - block_start_time >= min_block_duration or i == len(subtitles) - 1:
                    blocks.append({
                        "start_time": block_start_time,
                        "end_time": block_end_time,
                        "subtitles": current_block.copy(),
                        "content_text": current_block_text.strip(),
                        "title": ""  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –ø–æ–∑–∂–µ
                    })
                    current_block = []
                    current_block_text = ""
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –±–ª–æ–∫–æ–≤
    blocks = generate_block_titles(blocks, method="enhanced_keywords")
    
    return blocks


# –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–ª–æ–∫–æ–≤ —Å —É—á–µ—Ç–æ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≥–ª–∞–≤
def analyze_subtitles_into_blocks_with_chapters(subtitles, video_id, video_info=None, min_block_duration=60):
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç —Å—É–±—Ç–∏—Ç—Ä—ã –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –±–ª–æ–∫–∏ —Å —É—á–µ—Ç–æ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≥–ª–∞–≤ –≤–∏–¥–µ–æ
    
    Args:
        subtitles: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å—É–±—Ç–∏—Ç—Ä–æ–≤
        video_id: ID –≤–∏–¥–µ–æ YouTube
        video_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–∏–¥–µ–æ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        min_block_duration: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±–ª–æ–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        
    Returns:
        –°–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤, –≥–¥–µ –∫–∞–∂–¥—ã–π –±–ª–æ–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ø–∏—Å–æ–∫ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    """
    if not subtitles:
        return []
    
    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –≥–ª–∞–≤—ã –≤–∏–¥–µ–æ
    chapters = get_youtube_chapters(video_id)
    
    # –ï—Å–ª–∏ –≥–ª–∞–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã —á–µ—Ä–µ–∑ –ø–∞—Ä—Å–∏–Ω–≥, –ø—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ API (–µ—Å–ª–∏ –µ—Å—Ç—å –∫–ª—é—á)
    if not chapters:
        chapters = get_youtube_video_chapters_api(video_id)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–µ—á–Ω–æ–µ –≤—Ä–µ–º—è –≤–∏–¥–µ–æ
    video_end_time = 0
    if subtitles:
        last_subtitle = subtitles[-1]
        video_end_time = last_subtitle["start"] + last_subtitle.get("duration", 5)
    
    # –ï—Å–ª–∏ –≥–ª–∞–≤—ã –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–ª–æ–∫–æ–≤
    if chapters:
        logger.info(f"Using {len(chapters)} chapters from YouTube for blocks")
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –≤—Ä–µ–º–µ–Ω–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –≥–ª–∞–≤
        for i, chapter in enumerate(chapters):
            if chapter["end_time"] is None:
                if i < len(chapters) - 1:
                    chapter["end_time"] = chapters[i + 1]["start_time"]
                else:
                    chapter["end_time"] = video_end_time
        
        # –°–æ–∑–¥–∞–µ–º –±–ª–æ–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–ª–∞–≤
        blocks = []
        for chapter in chapters:
            start_time = chapter["start_time"]
            end_time = chapter["end_time"]
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—É–±—Ç–∏—Ç—Ä—ã –¥–ª—è —ç—Ç–æ–π –≥–ª–∞–≤—ã
            chapter_subtitles = [
                s for s in subtitles 
                if s["start"] >= start_time and s["start"] < end_time
            ]
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—É–±—Ç–∏—Ç—Ä—ã –∏–ª–∏ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è, —Å–æ–∑–¥–∞–µ–º –±–ª–æ–∫
            if chapter_subtitles or (end_time - start_time) >= min_block_duration:
                content_text = " ".join([s.get("text", "") for s in chapter_subtitles])
                
                blocks.append({
                    "start_time": start_time,
                    "end_time": end_time,
                    "subtitles": chapter_subtitles,
                    "content_text": content_text,
                    "title": chapter["title"]  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ YouTube
                })
        
        return blocks
    
    # –ï—Å–ª–∏ –≥–ª–∞–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º
    logger.info("No YouTube chapters found, using automatic block detection")
    return analyze_subtitles_into_blocks(subtitles, min_block_duration)


def generate_block_titles(blocks, method="enhanced_keywords"):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –±–ª–æ–∫–æ–≤ —Å—É–±—Ç–∏—Ç—Ä–æ–≤
    
    Args:
        blocks: –°–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤ —Å—É–±—Ç–∏—Ç—Ä–æ–≤
        method: –ú–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ ('enhanced_keywords', 'openai', 'first_sentence')
        
    Returns:
        –°–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤ —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
    """
    if method == "enhanced_keywords":
        # –£–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏ –ø–µ—Ä–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        try:
            import nltk
            from nltk.corpus import stopwords
            from nltk.tokenize import word_tokenize, sent_tokenize
            from collections import Counter
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ NLTK
            try:
                nltk.data.find('tokenizers/punkt')
            except LookupError:
                nltk.download('punkt', quiet=True)
            
            try:
                nltk.data.find('corpora/stopwords')
            except LookupError:
                nltk.download('stopwords', quiet=True)
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —è–∑—ã–∫–æ–≤
            try:
                stop_words_en = set(stopwords.words('english'))
            except:
                stop_words_en = set()
            
            try:
                stop_words_ru = set(stopwords.words('russian'))
            except:
                stop_words_ru = set()
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–æ–≤
            stop_words = stop_words_en.union(stop_words_ru)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–±—â–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
            additional_stop_words = {'yeah', 'uh', 'um', 'oh', 'like', 'just', 'so', 'know', 'think', 'well', 'going', 
                                    'get', 'got', 'actually', 'okay', 'right', 'thing', 'things', 'gonna', 'wanna'}
            stop_words = stop_words.union(additional_stop_words)
            
            for i, block in enumerate(blocks):
                text = block["content_text"].lower()
                
                # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
                sentences = sent_tokenize(text)
                first_sentence = sentences[0] if sentences else ""
                
                # –û—á–∏—â–∞–µ–º –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ (–±–µ—Ä–µ–º –Ω–µ –±–æ–ª–µ–µ 7 —Å–ª–æ–≤)
                clean_first_words = []
                for word in first_sentence.split()[:7]:
                    # –û—á–∏—â–∞–µ–º –æ—Ç –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
                    clean_word = ''.join(c for c in word if c.isalnum())
                    if clean_word and len(clean_word) > 1:
                        clean_first_words.append(clean_word)
                
                first_phrase = " ".join(clean_first_words)
                
                # –ù–∞—Ö–æ–¥–∏–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –≤—Å–µ–≥–æ –±–ª–æ–∫–∞
                words = word_tokenize(text)
                words = [word.lower() for word in words 
                         if word.isalnum() and word.lower() not in stop_words and len(word) > 2]
                
                word_counts = Counter(words)
                top_words = [word for word, count in word_counts.most_common(4) if count > 1]
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                if top_words and first_phrase:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—É—é —Ñ—Ä–∞–∑—É –∏ —Ç–æ–ø-–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                    if len(first_phrase) > 30:
                        first_phrase = first_phrase[:30] + "..."
                    
                    key_words = ", ".join(top_words[:3]) if top_words else ""
                    
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —á–∞—Å—Ç–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    title = first_phrase.capitalize()
                    if key_words:
                        title += f" [{key_words}]"
                elif first_phrase:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é —Ñ—Ä–∞–∑—É
                    title = first_phrase.capitalize()
                elif top_words:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                    title = "Topic: " + ", ".join(top_words[:4])
                else:
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–æ–ª–µ–∑–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                    title = f"Section {i+1}"
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∑–∞–≥–æ–ª–æ–≤–∫–∞
                if len(title) > 70:
                    title = title[:70] + "..."
                
                block["title"] = title
                
        except Exception as e:
            logger.warning(f"Error generating enhanced keyword titles: {e}")
            # Fallback: –ø—Ä–æ—Å—Ç–∞—è –Ω—É–º–µ—Ä–∞—Ü–∏—è —Ä–∞–∑–¥–µ–ª–æ–≤ —Å –ø–µ—Ä–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
            for i, block in enumerate(blocks):
                try:
                    text = block["content_text"]
                    first_words = " ".join(text.split()[:5])
                    block["title"] = f"Section {i+1}: {first_words}..."
                except:
                    block["title"] = f"Section {i+1}"
    
    elif method == "openai" and api_status.get("openai", False):
        # –ú–µ—Ç–æ–¥ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenAI –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        try:
            from langchain_openai import ChatOpenAI
            
            model = ChatOpenAI(
                model_name="gpt-3.5-turbo",
                temperature=0.3
            )
            
            for block in tqdm(blocks, desc="Generating titles with OpenAI"):
                content = block["content_text"]
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ –¥–ª—è API
                if len(content) > 2000:
                    content = content[:2000] + "..."
                
                try:
                    response = model.invoke(
                        f"Generate a concise, informative title (5-10 words) for this text segment from a video: '{content}'"
                    )
                    title = response.content.strip().strip('"\'')
                    block["title"] = title
                except Exception as e:
                    logger.warning(f"Error generating title with OpenAI: {e}")
                    # Fallback to simpler method
                    first_words = " ".join(content.split()[:7])
                    block["title"] = first_words + "..."
        except Exception as e:
            logger.error(f"Failed to use OpenAI for title generation: {e}")
            # Fallback to keywords method
            blocks = generate_block_titles(blocks, method="enhanced_keywords")
    
    elif method == "first_sentence":
        # –ü—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        try:
            import nltk
            from nltk.tokenize import sent_tokenize
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ NLTK
            try:
                nltk.data.find('tokenizers/punkt')
            except LookupError:
                nltk.download('punkt', quiet=True)
            
            for i, block in enumerate(blocks):
                text = block["content_text"]
                
                # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
                sentences = sent_tokenize(text)
                if sentences:
                    first_sent = sentences[0]
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                    if len(first_sent) > 60:
                        title = first_sent[:60] + "..."
                    else:
                        title = first_sent
                    block["title"] = title
                else:
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–±–∏—Ç—å –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                    first_words = " ".join(text.split()[:7])
                    block["title"] = f"Section {i+1}: {first_words}..."
        except Exception as e:
            logger.warning(f"Error generating first sentence titles: {e}")
            # Fallback: –ø—Ä–æ—Å—Ç–∞—è –Ω—É–º–µ—Ä–∞—Ü–∏—è —Ä–∞–∑–¥–µ–ª–æ–≤ —Å –ø–µ—Ä–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
            for i, block in enumerate(blocks):
                text = block["content_text"]
                first_words = " ".join(text.split()[:5])
                block["title"] = f"Section {i+1}: {first_words}..."
    
    else:
        # –ü—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–≤—ã—Ö —Å–ª–æ–≤
        for i, block in enumerate(blocks):
            try:
                content = block["content_text"]
                first_words = " ".join(content.split()[:7])
                if first_words:
                    block["title"] = first_words.capitalize() + "..."
                else:
                    block["title"] = f"Section {i+1}"
            except Exception as e:
                logger.warning(f"Error generating simple title for block {i}: {e}")
                block["title"] = f"Section {i+1}"
    
    return blocks



# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ generate_table_of_contents –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ YouTube –≥–ª–∞–≤
def generate_table_of_contents(blocks):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–ª–æ–∫–æ–≤ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    
    Args:
        blocks: –°–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤ —Å—É–±—Ç–∏—Ç—Ä–æ–≤
        
    Returns:
        –°—Ç—Ä–æ–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown —Å –æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ–º
    """
    toc = "# –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ –≤–∏–¥–µ–æ\n\n"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –±–ª–æ–∫–∏ —Å —Ñ–ª–∞–≥–æ–º YouTube –≥–ª–∞–≤
    has_youtube_chapters = any(block.get("is_youtube_chapter", False) for block in blocks)
    
    if has_youtube_chapters:
        toc += "> ‚ÑπÔ∏è –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–ª–∞–≤ YouTube\n\n"
    
    for i, block in enumerate(blocks):
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        start_time = format_time(block["start_time"])
        duration = format_time(block["end_time"] - block["start_time"])
        
        # –ü–æ–ª–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –±–µ–∑ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π
        title = block['title']
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–æ–∫ –¥–ª—è –≥–ª–∞–≤ YouTube
        chapter_icon = "üîñ " if block.get("is_youtube_chapter", False) else ""
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø—É–Ω–∫—Ç –æ–≥–ª–∞–≤–ª–µ–Ω–∏—è —Å –ø–µ—Ä–µ–Ω–æ—Å–æ–º —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        toc += f"### {i+1}. {chapter_icon}{title}\n"
        toc += f"**–í—Ä–µ–º—è:** {start_time} | **–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** {duration}\n\n"
    
    return toc

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≥–ª–∞–≤
def check_chapter_sources(video_id):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≥–ª–∞–≤ –¥–ª—è –≤–∏–¥–µ–æ
    
    Args:
        video_id: ID –≤–∏–¥–µ–æ YouTube
        
    Returns:
        dict: –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö –≥–ª–∞–≤
    """
    result = {
        "has_chapters": False,
        "sources": []
    }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≥–ª–∞–≤ —á–µ—Ä–µ–∑ –ø–∞—Ä—Å–∏–Ω–≥
    try:
        chapters = get_youtube_chapters(video_id)
        if chapters:
            result["has_chapters"] = True
            result["sources"].append("youtube_html")
            result["chapters_count"] = len(chapters)
    except Exception as e:
        logger.warning(f"Error checking HTML chapters: {e}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≥–ª–∞–≤ —á–µ—Ä–µ–∑ API
    try:
        api_chapters = get_youtube_video_chapters_api(video_id)
        if api_chapters:
            result["has_chapters"] = True
            result["sources"].append("youtube_api")
            result["api_chapters_count"] = len(api_chapters)
    except Exception as e:
        logger.warning(f"Error checking API chapters: {e}")
    
    return result


def display_toc_entry(block_index):
    """
    –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –±–ª–æ–∫–µ –¥–ª—è –æ–≥–ª–∞–≤–ª–µ–Ω–∏—è
    
    Args:
        block_index: –ò–Ω–¥–µ–∫—Å –±–ª–æ–∫–∞
        
    Returns:
        –°—Ç—Ä–æ–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –±–ª–æ–∫–µ
    """
    if not hasattr(app_state, 'subtitle_blocks') or not app_state.subtitle_blocks:
        return "–ë–ª–æ–∫–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –≤–∏–¥–µ–æ."
    
    try:
        block_index = int(block_index)
    except (ValueError, TypeError):
        return f"–ù–µ–≤–µ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –±–ª–æ–∫–∞: '{block_index}'. –î–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ."
    
    if block_index < 0 or block_index >= len(app_state.subtitle_blocks):
        return f"–û—à–∏–±–∫–∞: –∏–Ω–¥–µ–∫—Å –±–ª–æ–∫–∞ {block_index} –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ (0-{len(app_state.subtitle_blocks)-1})"
    
    try:
        block = app_state.subtitle_blocks[block_index]
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –±–ª–æ–∫–∞
        content = f"## {block.get('title', f'–ë–ª–æ–∫ {block_index+1}')}\n\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        if "start_time" in block and "end_time" in block:
            start_time = format_time(block['start_time'])
            end_time = format_time(block['end_time'])
            duration = format_time(block['end_time'] - block['start_time'])
            
            content += f"**–ù–∞—á–∞–ª–æ:** {start_time} | **–ö–æ–Ω–µ—Ü:** {end_time} | **–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** {duration}\n\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 100-200 —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞
        if "content_text" in block and block["content_text"]:
            preview_text = block["content_text"]
            if len(preview_text) > 200:
                preview_text = preview_text[:200] + "..."
            
            content += f"**–û–±–∑–æ—Ä —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ:**\n\n{preview_text}\n\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –≤ –±–ª–æ–∫–µ
        if "subtitles" in block and block["subtitles"]:
            content += f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –≤ –±–ª–æ–∫–µ:** {len(block['subtitles'])}\n\n"
        
        content += "–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É '–ü–æ–∫–∞–∑–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–ª–æ–∫–∞' –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."
        
        return content
    except Exception as e:
        logger.error(f"Error displaying TOC entry: {e}")
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –±–ª–æ–∫–µ: {str(e)}"


# –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è process_subtitles_with_blocks –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –≥–ª–∞–≤
def process_subtitles_with_blocks(subtitles, video_info):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—É–±—Ç–∏—Ç—Ä—ã, —Ä–∞–∑–±–∏–≤–∞—è –∏—Ö –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –±–ª–æ–∫–∏ –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É—è –æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ
    
    Args:
        subtitles: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å—É–±—Ç–∏—Ç—Ä–æ–≤
        video_info: –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤–∏–¥–µ–æ
        
    Returns:
        Tuple of (blocks, table_of_contents)
    """
    video_id = video_info.get("video_id") if video_info else None
    
    if video_id:
        # –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞–∑–±–∏—Ç—å —Å—É–±—Ç–∏—Ç—Ä—ã —Å —É—á–µ—Ç–æ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≥–ª–∞–≤
        blocks = analyze_subtitles_into_blocks_with_chapters(subtitles, video_id, video_info)
    else:
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –±–ª–æ–∫–∏
        blocks = analyze_subtitles_into_blocks(subtitles)
    
    # –ï—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–µ –±—ã–ª–∏ –∑–∞–¥–∞–Ω—ã –∏–∑ YouTube –≥–ª–∞–≤, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏—Ö
    for block in blocks:
        if not block["title"] or block["title"].startswith("Section "):
            # –ë–ª–æ–∫ –Ω–µ –∏–º–µ–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏–∑ YouTube, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º
            block["title"] = ""  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
    
    # –ë–ª–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–º –Ω—É–∂–Ω—ã –∑–∞–≥–æ–ª–æ–≤–∫–∏
    blocks_to_title = [b for b in blocks if not b["title"]]
    if blocks_to_title:
        titled_blocks = generate_block_titles(blocks_to_title, method="enhanced_keywords")
        
        # –ó–∞–º–µ–Ω—è–µ–º –±–ª–æ–∫–∏ –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –Ω–∞ –±–ª–æ–∫–∏ —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
        for i, block in enumerate(blocks):
            if not block["title"]:
                # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –±–ª–æ–∫ —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
                for titled_block in titled_blocks:
                    if titled_block["start_time"] == block["start_time"] and titled_block["end_time"] == block["end_time"]:
                        block["title"] = titled_block["title"]
                        break
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ
    toc = generate_table_of_contents(blocks)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–ª–æ–∫–∏ –∏ –æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    app_state.subtitle_blocks = blocks
    app_state.table_of_contents = toc
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±–ª–æ–∫–∞—Ö –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ
    if video_id:
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±–ª–æ–∫–∞—Ö (–±–µ–∑ –ø–æ–ª–Ω—ã—Ö —Å—É–±—Ç–∏—Ç—Ä–æ–≤)
            blocks_metadata = []
            for block in blocks:
                blocks_metadata.append({
                    "start_time": block["start_time"],
                    "end_time": block["end_time"],
                    "title": block["title"],
                    "is_youtube_chapter": block.get("is_youtube_chapter", False)
                })
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±–ª–æ–∫–∞—Ö –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤–∏–¥–µ–æ
            video_info["blocks"] = blocks_metadata
            video_info["has_youtube_chapters"] = any(b.get("is_youtube_chapter", False) for b in blocks)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            save_video_metadata(video_id, video_info)
        except Exception as e:
            logger.warning(f"Failed to save blocks metadata: {e}")
    
    return blocks, toc

# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ get_block_content –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
def get_block_content(block_index):
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–ª–æ–∫–∞ –ø–æ –µ–≥–æ –∏–Ω–¥–µ–∫—Å—É
    
    Args:
        block_index: –ò–Ω–¥–µ–∫—Å –±–ª–æ–∫–∞
        
    Returns:
        –°—Ç—Ä–æ–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º –±–ª–æ–∫–∞
    """
    if not hasattr(app_state, 'subtitle_blocks') or not app_state.subtitle_blocks:
        return "–ë–ª–æ–∫–∏ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –≤–∏–¥–µ–æ."
    
    try:
        block_index = int(block_index)
    except (ValueError, TypeError):
        return f"–ù–µ–≤–µ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –±–ª–æ–∫–∞: '{block_index}'. –î–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ."
    
    if block_index < 0 or block_index >= len(app_state.subtitle_blocks):
        return f"–û—à–∏–±–∫–∞: –∏–Ω–¥–µ–∫—Å –±–ª–æ–∫–∞ {block_index} –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ (0-{len(app_state.subtitle_blocks)-1})"
    
    try:
        block = app_state.subtitle_blocks[block_index]
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–ª–æ–∫–∞
        content = f"## {block.get('title', f'–ë–ª–æ–∫ {block_index+1}')}\n\n"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
        if "start_time" in block and "end_time" in block:
            content += f"**–í—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞:** {format_time(block['start_time'])} - {format_time(block['end_time'])}\n\n"
        
        content += "### –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:\n\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—É–±—Ç–∏—Ç—Ä—ã –±–ª–æ–∫–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
        if "subtitles" in block and block["subtitles"]:
            for subtitle in block["subtitles"]:
                if "start" in subtitle:
                    timestamp = format_time(subtitle["start"])
                    text = subtitle.get("text", "")
                    content += f"**[{timestamp}]** {text}\n\n"
        else:
            # –ï—Å–ª–∏ —Å—É–±—Ç–∏—Ç—Ä—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –±–ª–æ–∫–∞
            content += block.get("content_text", "–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ.")
        
        return content
    except Exception as e:
        logger.error(f"Error getting block content: {e}")
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –±–ª–æ–∫–∞: {str(e)}"

